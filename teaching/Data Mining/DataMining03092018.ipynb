{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "# Data Mining  [EN.550.636.02]\n",
    "\n",
    "03/09/2018\n",
    "\n",
    "**TA** - Cong Mu (cmu2@jhu.edu)   <br/>\n",
    "**Office Hour** - Monday 9:00am ~ 11:00am\n",
    "\n",
    "- **Python:** scikit-learn\n",
    "- **Classification:** NB, LDA, QDA\n",
    "- **Q & A**\n",
    "\n",
    "<hr/>\n",
    "\n",
    "\n",
    "[Install Python](https://www.python.org/) <br/>\n",
    "[Install Anaconda](https://www.continuum.io/downloads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"darkblue\">Python</font></h2>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn\n",
    "[Tutorial](http://scikit-learn.org/stable/tutorial/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "[Reference](http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Standardization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.88234931,  0.10432774,  0.90700933],\n",
       "       [ 0.3063989 ,  0.44640887,  0.58998539],\n",
       "       [ 0.8371111 ,  0.69780061,  0.80280284],\n",
       "       [ 0.10721508,  0.75709253,  0.99967101],\n",
       "       [ 0.725931  ,  0.14144824,  0.3567206 ],\n",
       "       [ 0.94270411,  0.61016189,  0.22757747],\n",
       "       [ 0.66873237,  0.69290455,  0.41686251],\n",
       "       [ 0.17180956,  0.97689051,  0.33022414],\n",
       "       [ 0.62904415,  0.16061095,  0.08995264],\n",
       "       [ 0.97082236,  0.81657757,  0.57136573],\n",
       "       [ 0.34585315,  0.403744  ,  0.13738304],\n",
       "       [ 0.90093449,  0.93393613,  0.04737714],\n",
       "       [ 0.67150688,  0.03483186,  0.25269136],\n",
       "       [ 0.55712505,  0.52582348,  0.35296779],\n",
       "       [ 0.09298297,  0.30450898,  0.86242986],\n",
       "       [ 0.71693654,  0.96407149,  0.53970186],\n",
       "       [ 0.95053982,  0.66798156,  0.87424103],\n",
       "       [ 0.48120492,  0.13739854,  0.69022154],\n",
       "       [ 0.50211855,  0.07451108,  0.52351229],\n",
       "       [ 0.91856772,  0.5274287 ,  0.36424787]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2018)\n",
    "X = np.random.rand(20, 3)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = preprocessing.scale(X, axis=0, with_mean=True, with_std=True, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -6.66133815e-17,   3.19189120e-17,   3.60822483e-17])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether mean = 0\n",
    "X_scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether std = 1\n",
    "X_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Binarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.,  2.],\n",
       "       [ 2.,  0.,  0.],\n",
       "       [ 0.,  1., -1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[ 1., -1.,  2.],\n",
    "              [ 2.,  0.,  0.],\n",
    "              [ 0.,  1., -1.]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer = preprocessing.Binarizer(threshold=0.0, copy=True)\n",
    "binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer = preprocessing.Binarizer(threshold=1.5, copy=True)\n",
    "binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Custom transformers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0, 1], [2, 3]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.69314718],\n",
       "       [ 1.09861229,  1.38629436]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Could be useful in pipeline\n",
    "transformer = preprocessing.FunctionTransformer(np.log1p) # log(1 + x)\n",
    "transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.69314718],\n",
       "       [ 1.09861229,  1.38629436]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log1p(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"darkblue\">Model</font></h2>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "c = np.unique(iris.target)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "[Reference](http://scikit-learn.org/stable/modules/naive_bayes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure of Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit\n",
    "> Estimate the parameters in each class\n",
    "\n",
    "- Predict\n",
    "> For each unlabeled data, calculate the posterior for each class\n",
    ">\n",
    "> Classify the data with class k having the largest posterior\n",
    "\n",
    "- Assumption\n",
    "> Features are independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy example for Gaussian Naive Bayes\n",
    "\n",
    "class GNB(dict):\n",
    "    \n",
    "    def fit(self, X, C):\n",
    "        for k in np.unique(C):\n",
    "            # Observation in class k\n",
    "            members = (C == k)\n",
    "            # Number of obvervation in class k\n",
    "            num = members.sum() \n",
    "            # Use frequency as prior\n",
    "            prior = num / float(C.size)\n",
    "            # Choose the observation in class k\n",
    "            XX = X[members,:] \n",
    "            # Calculate mean for class k\n",
    "            mu = XX.mean(axis=0)\n",
    "            # Center\n",
    "            XX -= mu\n",
    "            # Calculate variance for class k\n",
    "            var = (XX*XX).sum(axis=0) / (XX.shape[0]-1)\n",
    "            # Save the result for class k\n",
    "            self[k] = (prior, num, mu, var)\n",
    "    \n",
    "    def predict(self, Y):\n",
    "        pred = -1 * ones(Y.shape[0])\n",
    "        for i in range(pred.size):\n",
    "            # Initialization\n",
    "            pmax, kmax = -1, None   \n",
    "            # Calculate the posterior for each class\n",
    "            for k in self:\n",
    "                prior, num, mu, var = self[k]\n",
    "                diff = Y[i,:] - mu\n",
    "                d2 = diff*diff / (2*var) \n",
    "                posterior = prior * np.exp(-d2.sum()) / np.sqrt(np.prod(2*pi*var))\n",
    "                # Update the threshold and prediction with the largest posterior\n",
    "                if posterior > pmax:\n",
    "                    pmax = posterior\n",
    "                    kmax = k\n",
    "                pred[i] = kmax\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: GNB\n",
      "Number of mislabeled points out of a total 150 points : 6\n",
      "Accuracy:  0.96\n"
     ]
    }
   ],
   "source": [
    "clf = GNB()\n",
    "clf.fit(iris.data, iris.target)\n",
    "pred = clf.predict(iris.data)\n",
    "\n",
    "print('Classifier: GNB')\n",
    "print('Number of mislabeled points out of a total %d points : %d' % (iris.target.size, (iris.target!=pred).sum()))\n",
    "print('Accuracy: ', mean(iris.target==pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: GNB\n",
      "Number of mislabeled points out of a total 150 points : 6\n",
      "Accuracy:  0.96\n"
     ]
    }
   ],
   "source": [
    "# Specify the model\n",
    "clf = GaussianNB(priors=None)\n",
    "\n",
    "# Fit\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "# Predict\n",
    "pred = clf.predict(iris.data)\n",
    "\n",
    "print('Classifier: GNB')\n",
    "print('Number of mislabeled points out of a total %d points : %d' % (iris.target.size, (iris.target!=pred).sum()))\n",
    "print('Accuracy: ', mean(iris.target==pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis & Quadratic Discriminant Analysis\n",
    "[Reference](http://scikit-learn.org/stable/modules/lda_qda.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure of LDA & QDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit\n",
    "> Estimate the parameters in each class\n",
    "\n",
    "- Predict\n",
    "> For each unlabeled data, calculate the log-likelihood for each class\n",
    ">\n",
    "> Classify the data with class k having the largest log-likelihood\n",
    "\n",
    "- Difference\n",
    "> LDA: same covariance matrix in different classes\n",
    ">\n",
    "> QDA: different covariance matrix in different classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy example for Quadratic Discriminant Analysis\n",
    "\n",
    "class QDA(dict):\n",
    "    \n",
    "    def fit(self, X, C):\n",
    "        for k in np.unique(C):\n",
    "            # Observation in class k\n",
    "            members = (C==k)\n",
    "            # Number of obvervation in class k\n",
    "            num = members.sum() \n",
    "            # Use frequency as prior\n",
    "            prior = num / float(C.size)\n",
    "            # Choose the observation in class k\n",
    "            S = X[members,:] \n",
    "            # Calculate mean for class k\n",
    "            mu = S.mean(axis=0)    \n",
    "            # Center\n",
    "            Z = (S-mu).T\n",
    "            # Calculate variance for class k\n",
    "            cov = Z.dot(Z.T) / (Z[0,:].size-1)\n",
    "            # Save the result for class k\n",
    "            self[k] = (num, prior, mu, cov)\n",
    "\n",
    "            \n",
    "    def predict(self, Y):\n",
    "        pred = -1 * ones(Y.shape[0])\n",
    "        for i in range(pred.size):\n",
    "            # Initialization\n",
    "            d2min, kbest = 1e99, None\n",
    "            # Calculate the log-likelihood for each class\n",
    "            for k in self: \n",
    "                num, prior, mu, cov = self[k]\n",
    "                diff = (Y[i,:]-mu).T\n",
    "                d2 = diff.T.dot(linalg.inv(cov)).dot(diff) / 2\n",
    "                d2 += np.log(linalg.det(cov)) / 2 - np.log(prior) \n",
    "                # Update the threshold and prediction with the largest log-likelihood\n",
    "                if d2 < d2min: \n",
    "                    d2min, kbest = d2,k\n",
    "            pred[i] = kbest\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: QDA\n",
      "Number of mislabeled points out of a total 150 points : 3\n",
      "Accuracy:  0.98\n"
     ]
    }
   ],
   "source": [
    "clf = QDA()\n",
    "clf.fit(iris.data, iris.target)\n",
    "pred = clf.predict(iris.data)\n",
    "\n",
    "print('Classifier: QDA')\n",
    "print('Number of mislabeled points out of a total %d points : %d' % (iris.target.size, (iris.target!=pred).sum()))\n",
    "print('Accuracy: ', mean(iris.target==pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LDA\n",
      "Number of mislabeled points out of a total 150 points : 3\n",
      "Accuracy:  0.98\n"
     ]
    }
   ],
   "source": [
    "# Specify the model\n",
    "clf = LinearDiscriminantAnalysis(priors=None)\n",
    "\n",
    "# Fit\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "# Predict\n",
    "pred = clf.predict(iris.data)\n",
    "\n",
    "print('Classifier: LDA')\n",
    "print('Number of mislabeled points out of a total %d points : %d' % (iris.target.size, (iris.target!=pred).sum()))\n",
    "print('Accuracy: ', mean(iris.target==pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: QDA\n",
      "Number of mislabeled points out of a total 150 points : 3\n",
      "Accuracy:  0.98\n"
     ]
    }
   ],
   "source": [
    "# Specify the model\n",
    "clf = QuadraticDiscriminantAnalysis(priors=None)\n",
    "\n",
    "# Fit\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "# Predict\n",
    "pred = clf.predict(iris.data)\n",
    "\n",
    "print('Classifier: QDA')\n",
    "print('Number of mislabeled points out of a total %d points : %d' % (iris.target.size, (iris.target!=pred).sum()))\n",
    "print('Accuracy: ', mean(iris.target==pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
