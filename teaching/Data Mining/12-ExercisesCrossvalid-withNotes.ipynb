{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<hr/>\n",
    "\n",
    "# Data Mining\n",
    "**Tamás Budavári** - budavari@jhu.edu <br/>\n",
    "\n",
    "- Classification exercises\n",
    "- Cross-validation\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"darkblue\">Classification</font></h1>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Based on a **training set** of labeled points, assign class labels to unknown vectors in the **query set**.  \n",
    "\n",
    "> **Training set**\n",
    "\n",
    ">$T = \\big\\{ (x_i, C_i) \\big\\}$ \n",
    "\n",
    "> where $x_i\\in \\mathbb{R}^d$ are feature sets and $C_i$ are the known class memberships\n",
    "\n",
    "<nbsp/>\n",
    "\n",
    "> **Query set**\n",
    "\n",
    ">$Q = \\big\\{ x_i \\big\\}$ where $x_i\\in \\mathbb{R}^d$ consist of the kind of features in $T$\n",
    "\n",
    "- And again, $x_i$ are not real vectors but **feature sets** of a bunch of scalars in general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes with Covariance Matrix\n",
    "\n",
    "- Estimate the full covariance matrix for the classes\n",
    "\n",
    ">$\\displaystyle {\\cal{}L}_{\\boldsymbol{x}}(C_k) =  G(\\boldsymbol{x};\\mu_k, \\Sigma_k)$\n",
    "\n",
    "> Handles correlated features well\n",
    "\n",
    "- Consider binary problem with 2 classes\n",
    "\n",
    "> Taking the negative logarithm of the likelihoods we compare\n",
    "\n",
    ">$\\displaystyle (x\\!-\\!\\mu_1)^T\\,\\Sigma_1^{-1}(x\\!-\\!\\mu_1) + \\ln\\,\\lvert \\Sigma_1  \\lvert $ vs.\n",
    "\n",
    ">$\\displaystyle (x\\!-\\!\\mu_2)^T\\,\\Sigma_2^{-1}(x\\!-\\!\\mu_2) + \\ln \\, \\lvert\\Sigma_2\\lvert $\n",
    "\n",
    "> If the difference is lower than a threshold, we classify it accordingly\n",
    "\n",
    "- This is called [**Quadratic Discriminant Analysis**](https://scikit-learn.org/stable/modules/lda_qda.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same Covariance Matrix\n",
    "\n",
    "- When $\\Sigma_1=\\Sigma_2=\\Sigma$, the quadratic terms cancel from the difference\n",
    " \n",
    ">$\\displaystyle (x\\!-\\!\\mu_1)^T\\,\\Sigma^{-1}(x\\!-\\!\\mu_1) $ \n",
    ">$\\displaystyle -\\ (x\\!-\\!\\mu_2)^T\\,\\Sigma^{-1}(x\\!-\\!\\mu_2) $\n",
    "\n",
    "- Hence this is called [**Linear Discriminant Analysis**](https://scikit-learn.org/stable/modules/lda_qda.html)\n",
    "\n",
    "> Fewer parameters to estimate during the learning process\n",
    "\n",
    "> Good, if we don't have enough data, for example...\n",
    "\n",
    "> Think linear vs quadratic fitting and how you decide between those"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: QDA \n",
    "\n",
    "- Use the provided [training](Class-Train.csv) and [query](Class-Query.csv) sets to perform classification\n",
    "\n",
    "> **Training** set consists of 3 columns of ($x_i$, $y_i$, $C_i$)\n",
    "\n",
    "> **Query** set only has 2 columns of ($x_i$, $y_i$)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyQDA(object):\n",
    "    \"\"\" Template for classifier\n",
    "    \"\"\"\n",
    "    def fit(self,X,C):\n",
    "        # your code here\n",
    "        return self\n",
    "\n",
    "    def predict(self,Y):\n",
    "        Cpred = None\n",
    "        # your code here\n",
    "        # use linalg.det(matrix)\n",
    "        # and linalg.inv(matrix)\n",
    "        return Cpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyQDA(object):\n",
    "    \"\"\" Simple implementation for illustration purposes\n",
    "    \"\"\"       \n",
    "    def fit(self,X,C):\n",
    "        self.param = dict()\n",
    "        for k in np.unique(C):\n",
    "            members = (C==k)\n",
    "            prior = members.sum() / float(C.size)\n",
    "            S = X[members,:] # subset of class \n",
    "            mu = S.mean(axis=0)    \n",
    "            Z = (S-mu).T # centered column vectors\n",
    "            cov = Z.dot(Z.T) / (Z[0,:].size-1)\n",
    "            self.param[k] = (mu,cov,prior)\n",
    "        return self\n",
    "            \n",
    "    def predict(self,Y):\n",
    "        Cpred = -1 * ones(Y[:,0].size)\n",
    "        for i in range(Cpred.size):\n",
    "            d2min, kbest = 1e99, None\n",
    "            for k in self.param:\n",
    "                mu, cov, prior = self.param[k]\n",
    "                diff = (Y[i,:]-mu).T\n",
    "                d2 = diff.T.dot(linalg.inv(cov)).dot(diff) / 2\n",
    "                d2 += np.log(linalg.det(cov)) / 2 - np.log(prior) \n",
    "                if d2<d2min: d2min,kbest = d2,k\n",
    "            Cpred[i] = kbest\n",
    "        return Cpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different estimates: 0\n"
     ]
    }
   ],
   "source": [
    "# reference implementation\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "D = np.loadtxt('files/Class-Train.csv', delimiter=',')\n",
    "Q = np.loadtxt('files/Class-Query.csv', delimiter=',')\n",
    "X, C = D[:,0:2], D[:,2]\n",
    "\n",
    "Cpred = MyQDA().fit(X,C).predict(Q)\n",
    "Cskit =   QDA().fit(X,C).predict(Q)\n",
    "\n",
    "print ('Number of different estimates:', (Cpred!=Cskit).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"darkblue\">Cross-Validation</font></h1>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- How to evaluate the quality of estimator?\n",
    "\n",
    "> $k$-NN method's parameter affects the results\n",
    "\n",
    "- We saw on the IRIS data that 1-NN was overfitting\n",
    "\n",
    "> We discussed excluding the point itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitions of the Training set\n",
    "\n",
    "- Random complementary subsets \n",
    "\n",
    "> Train on a larger subset, test on a small\n",
    "\n",
    "> Multiple rounds to decrease variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out\n",
    "\n",
    "- For each point, we train on the others and test\n",
    "\n",
    "> Testing on $n$ points requires $n$ training \n",
    "\n",
    "- Expensive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A Relaxed Variant\n",
    "\n",
    "- $k$-fold cross-validation \n",
    "\n",
    "> 0. Create $k$ partitions of equal sizes, e.g., $k=2$ yields two subsets\n",
    "> 0. Pick a single partition and train on the other $(k\\!-\\!1)$ \n",
    "> 0. Repeat for all $k$ partitions - requires $k$ trainings\n",
    "\n",
    "- Leave-One-Out is a special case with $k=n$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Cross-Validation\n",
    "\n",
    "- Evaluate \"QDA\" on the [training](files/Class-Train.csv) set using 2-fold cross-validation\n",
    "\n",
    ">0. What is the fraction of correct estimates? \n",
    ">0. What is the uncertainty of that fraction?\n",
    " \n",
    "> The **training** set consists of 3 columns of ($x_i$, $y_i$, $C_i$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dc = D.copy()\n",
    "# randomize and split to D1 + D2\n",
    "np.random.seed(seed=42)\n",
    "np.random.shuffle(Dc)\n",
    "split = int(Dc[:,0].size/2)\n",
    "D1, D2 = Dc[:split,:], Dc[split:,:]\n",
    "\n",
    "# train on one, estimate on the other\n",
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case #0 - Number of mislabeled points out of a total 157 points : 19\n",
      "Case #1 - Number of mislabeled points out of a total 156 points : 20\n"
     ]
    }
   ],
   "source": [
    "Dc = D.copy()\n",
    "# randomize and split to D1 + D2\n",
    "np.random.seed(seed=42)\n",
    "np.random.shuffle(Dc)\n",
    "split = int(Dc[:,0].size/2)\n",
    "D1, D2 = Dc[:split,:], Dc[split:,:]\n",
    "# train on one estimate or the other\n",
    "for i,(T,Q) in enumerate([(D1,D2),(D2,D1)]):\n",
    "    X, C = T[:,0:2], T[:,2]\n",
    "    Cpred, Ctrue = MyQDA().fit(X,C).predict(Q[:,:2]), Q[:,2]\n",
    "    print (\"Case #%d - Number of mislabeled points out of a total %3d points : %2d\" \\\n",
    "        % (i, Q.shape[0],(Ctrue!=Cpred).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done already?\n",
    "\n",
    "- Visualize the results in the 2D features space\n",
    "- Make these simple codes run faster \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-fold CV - quick hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 (208, 3)\n",
      "10 (209, 3)\n",
      "17 (209, 3)\n"
     ]
    }
   ],
   "source": [
    "Dc = D.copy()\n",
    "\n",
    "# randomize and split to D1 + D2\n",
    "np.random.seed(seed=42)\n",
    "np.random.shuffle(Dc)\n",
    "split = int(Dc[:,0].size/3)\n",
    "split2 = 2*split\n",
    "D1, D2, D3 = Dc[:split,:], Dc[split:split2,:], Dc[split2:]\n",
    "\n",
    "# train on one, estimate on the other\n",
    "for T,Q in [ (np.vstack([D1,D2]),D3), (np.vstack([D2,D3]),D1), (np.vstack([D3,D1]),D2)]:\n",
    "    Cpred = QDA().fit(T[:,:2],T[:,2]).predict(Q[:,:2])\n",
    "    Ctrue = Q[:,2]\n",
    "    print ((Cpred!=Ctrue).sum(), T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unhomework\n",
    "\n",
    "- Implement LDA and compare to sklearn\n",
    "\n",
    ">0. Write code without using sklearn \n",
    ">0. Apply to [training](Class-Train.csv) and [query](Class-Query.csv) sets \n",
    ">0. Compare your results to sklearn's \n",
    "\n",
    "- Perform 10-fold cross-validation of *MyQDA* on [this](Class-Train.csv) file\n",
    "\n",
    ">0. Write code without using sklearn \n",
    ">0. Calculate average and variance of good classifications \n",
    ">0. Compare to sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82352941, 0.82352941, 0.82352941, 0.875     , 0.73333333,\n",
       "       0.8       , 1.        , 1.        , 1.        , 0.93333333])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = QDA()\n",
    "cross_val_score(clf, X,C, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\t 0.8125   =   0.8125\n",
      "1 :\t 0.875   =   0.875\n",
      "2 :\t 0.75   =   0.75\n",
      "3 :\t 0.875   =   0.875\n",
      "4 :\t 0.8125   =   0.8125\n",
      "5 :\t 0.75   =   0.75\n",
      "6 :\t 1.0   =   1.0\n",
      "7 :\t 1.0   =   1.0\n",
      "8 :\t 0.9333333333333333   =   0.9333333333333333\n",
      "9 :\t 1.0   =   1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k_fold = KFold(n_splits=10, shuffle=False) \n",
    "\n",
    "for k, (train, test) in enumerate(k_fold.split(X)):\n",
    "    clf.fit(X[train],C[train])\n",
    "    Cpred = clf.predict(X[test])\n",
    "    print (k, ':\\t', (C[test]==Cpred).sum() / float(test.size),\n",
    "        '  =  ', clf.score(X[test],C[test]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"darkblue\">Summary</font></h1>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "c = np.unique(iris.target)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure of [LDA & QDA](http://scikit-learn.org/stable/modules/lda_qda.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit\n",
    "> Estimate the parameters in each class\n",
    "\n",
    "- Predict\n",
    "> For each unlabeled data, calculate the log-likelihood for each class\n",
    ">\n",
    "> Classify the data with class k having the largest log-likelihood\n",
    "\n",
    "- Difference\n",
    "> LDA: same covariance matrix in different classes\n",
    ">\n",
    "> QDA: different covariance matrix in different classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy example for Quadratic Discriminant Analysis\n",
    "\n",
    "class QDA(dict):\n",
    "    \n",
    "    def fit(self, X, C):\n",
    "        for k in np.unique(C):\n",
    "            # Observation in class k\n",
    "            members = (C==k)\n",
    "            # Number of obvervation in class k\n",
    "            num = members.sum() \n",
    "            # Use frequency as prior\n",
    "            prior = num / float(C.size)\n",
    "            # Choose the observation in class k\n",
    "            S = X[members,:] \n",
    "            # Calculate mean for class k\n",
    "            mu = S.mean(axis=0)    \n",
    "            # Center\n",
    "            Z = (S-mu).T\n",
    "            # Calculate variance for class k\n",
    "            cov = Z.dot(Z.T) / (Z[0,:].size-1)\n",
    "            # Save the result for class k\n",
    "            self[k] = (num, prior, mu, cov)\n",
    "\n",
    "            \n",
    "    def predict(self, Y):\n",
    "        pred = -1 * ones(Y.shape[0])\n",
    "        for i in range(pred.size):\n",
    "            # Initialization\n",
    "            d2min, kbest = 1e99, None\n",
    "            # Calculate the log-likelihood for each class\n",
    "            for k in self: \n",
    "                num, prior, mu, cov = self[k]\n",
    "                diff = (Y[i,:]-mu).T\n",
    "                d2 = diff.T.dot(linalg.inv(cov)).dot(diff) / 2\n",
    "                d2 += np.log(linalg.det(cov)) / 2 - np.log(prior) \n",
    "                # Update the threshold and prediction with the largest log-likelihood\n",
    "                if d2 < d2min: \n",
    "                    d2min, kbest = d2,k\n",
    "            pred[i] = kbest\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: QDA\n",
      "Number of mislabeled points out of a total 150 points : 3\n",
      "Accuracy:  0.98\n"
     ]
    }
   ],
   "source": [
    "clf = QDA()\n",
    "clf.fit(iris.data, iris.target)\n",
    "pred = clf.predict(iris.data)\n",
    "\n",
    "print('Classifier: QDA')\n",
    "print('Number of mislabeled points out of a total %d points : %d' % (iris.target.size, (iris.target!=pred).sum()))\n",
    "print('Accuracy: ', mean(iris.target==pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LDA\n",
      "Number of mislabeled points out of a total 150 points : 3\n",
      "Accuracy:  0.98\n"
     ]
    }
   ],
   "source": [
    "# Specify the model\n",
    "clf = LinearDiscriminantAnalysis(priors=None)\n",
    "\n",
    "# Fit\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "# Predict\n",
    "pred = clf.predict(iris.data)\n",
    "\n",
    "print('Classifier: LDA')\n",
    "print('Number of mislabeled points out of a total %d points : %d' % (iris.target.size, (iris.target!=pred).sum()))\n",
    "print('Accuracy: ', mean(iris.target==pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: QDA\n",
      "Number of mislabeled points out of a total 150 points : 3\n",
      "Accuracy:  0.98\n"
     ]
    }
   ],
   "source": [
    "# Specify the model\n",
    "clf = QuadraticDiscriminantAnalysis(priors=None)\n",
    "\n",
    "# Fit\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "# Predict\n",
    "pred = clf.predict(iris.data)\n",
    "\n",
    "print('Classifier: QDA')\n",
    "print('Number of mislabeled points out of a total %d points : %d' % (iris.target.size, (iris.target!=pred).sum()))\n",
    "print('Accuracy: ', mean(iris.target==pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Split Training Data and Test Data](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.arange(10)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1],\n",
       "       [ 2,  3],\n",
       "       [ 4,  5],\n",
       "       [ 6,  7],\n",
       "       [ 8,  9],\n",
       "       [10, 11],\n",
       "       [12, 13],\n",
       "       [14, 15],\n",
       "       [16, 17],\n",
       "       [18, 19]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(20).reshape(10, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: \n",
      " [[16 17]\n",
      " [18 19]\n",
      " [ 8  9]\n",
      " [10 11]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [12 13]]\n",
      "X_test: \n",
      " [[ 0  1]\n",
      " [ 6  7]\n",
      " [14 15]]\n",
      "Y_train: \n",
      " [8 9 4 5 1 2 6]\n",
      "Y_test: \n",
      " [0 3 7]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=2018)\n",
    "print('X_train: \\n', X_train)\n",
    "print('X_test: \\n', X_test)\n",
    "print('Y_train: \\n', Y_train)\n",
    "print('Y_test: \\n', Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: \n",
      " [[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]\n",
      " [12 13]]\n",
      "X_test: \n",
      " [[14 15]\n",
      " [16 17]\n",
      " [18 19]]\n",
      "Y_train: \n",
      " [0 1 2 3 4 5 6]\n",
      "Y_test: \n",
      " [7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# If you don't want to shuffle\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=2018, shuffle=False)\n",
    "print('X_train: \\n', X_train)\n",
    "print('X_test: \\n', X_test)\n",
    "print('Y_train: \\n', Y_train)\n",
    "print('Y_test: \\n', Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Cross-Validation](http://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features\n",
    "wine.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "wine.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([59, 71, 48]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many class and how many observation in each class\n",
    "np.unique(wine.target, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.68421053  0.55555556  0.72222222  0.66666667  0.66666667  0.66666667\n",
      "  0.72222222  0.77777778  0.88235294  0.875     ]\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "cvscores = cross_val_score(estimator=knn, X=wine.data, y=wine.target, cv=10)\n",
    "print(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72193412452700367"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively\n",
    "\n",
    "# Split dataset into k consecutive folds (without shuffling by default).\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# The folds are made by preserving the percentage of samples for each class\n",
    "from sklearn.model_selection import StratifiedKFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1: [ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177]\n",
      "Fold2: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  59  60  61  62  63  64\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  88  89  90  91  92  93  94 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153]\n",
      "\n",
      "\n",
      "Fold1: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  59  60  61  62  63  64\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  88  89  90  91  92  93  94 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153]\n",
      "Fold2: [ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=2, shuffle=False, random_state=2018) # random_state used when shuffle == True.\n",
    "for fold1_index, fold2_index in skf.split(wine.data, wine.target):\n",
    "    print('Fold1:', fold1_index)\n",
    "    print('Fold2:', fold2_index)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1:\n",
      "(array([0, 1, 2]), array([30, 36, 24]))\n",
      "Fold2:\n",
      "(array([0, 1, 2]), array([29, 35, 24]))\n"
     ]
    }
   ],
   "source": [
    "# The distribution of each class in each folds\n",
    "y_fold1 = wine.target[fold1_index]\n",
    "y_fold2 = wine.target[fold2_index]\n",
    "print('Fold1:')\n",
    "print(np.unique(y_fold1, return_counts=True))\n",
    "print('Fold2:')\n",
    "print(np.unique(y_fold2, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1: [  0   4   6   9  16  19  22  25  26  27  29  31  34  38  40  42  43  44\n",
      "  45  46  47  49  50  55  59  60  61  65  67  70  71  72  73  74  75  76\n",
      "  77  79  83  86  87  88  93  96  97  98  99 100 102 103 104 105 109 113\n",
      " 114 117 119 120 122 123 126 127 128 130 134 135 137 141 142 145 147 148\n",
      " 149 150 151 152 153 154 156 157 159 160 163 164 170 171 172 175 177]\n",
      "Fold2: [  1   2   3   5   7   8  10  11  12  13  14  15  17  18  20  21  23  24\n",
      "  28  30  32  33  35  36  37  39  41  48  51  52  53  54  56  57  58  62\n",
      "  63  64  66  68  69  78  80  81  82  84  85  89  90  91  92  94  95 101\n",
      " 106 107 108 110 111 112 115 116 118 121 124 125 129 131 132 133 136 138\n",
      " 139 140 143 144 146 155 158 161 162 165 166 167 168 169 173 174 176]\n",
      "\n",
      "\n",
      "Fold1: [  1   2   3   5   7   8  10  11  12  13  14  15  17  18  20  21  23  24\n",
      "  28  30  32  33  35  36  37  39  41  48  51  52  53  54  56  57  58  62\n",
      "  63  64  66  68  69  78  80  81  82  84  85  89  90  91  92  94  95 101\n",
      " 106 107 108 110 111 112 115 116 118 121 124 125 129 131 132 133 136 138\n",
      " 139 140 143 144 146 155 158 161 162 165 166 167 168 169 173 174 176]\n",
      "Fold2: [  0   4   6   9  16  19  22  25  26  27  29  31  34  38  40  42  43  44\n",
      "  45  46  47  49  50  55  59  60  61  65  67  70  71  72  73  74  75  76\n",
      "  77  79  83  86  87  88  93  96  97  98  99 100 102 103 104 105 109 113\n",
      " 114 117 119 120 122 123 126 127 128 130 134 135 137 141 142 145 147 148\n",
      " 149 150 151 152 153 154 156 157 159 160 163 164 170 171 172 175 177]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=2, shuffle=True, random_state=2018) # random_state used when shuffle == True.\n",
    "for fold1_index, fold2_index in kf.split(wine.data, wine.target):\n",
    "    print('Fold1:', fold1_index)\n",
    "    print('Fold2:', fold2_index)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1:\n",
      "(array([0, 1, 2]), array([35, 32, 22]))\n",
      "Fold2:\n",
      "(array([0, 1, 2]), array([24, 39, 26]))\n"
     ]
    }
   ],
   "source": [
    "# The distribution of each class in each folds\n",
    "y_fold1 = wine.target[fold1_index]\n",
    "y_fold2 = wine.target[fold2_index]\n",
    "print('Fold1:')\n",
    "print(np.unique(y_fold1, return_counts=True))\n",
    "print('Fold2:')\n",
    "print(np.unique(y_fold2, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=\"red\">**NOTE**: </font> Be careful of the unbalanced when split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
